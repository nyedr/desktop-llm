# Ollama Configuration
OLLAMA_BASE_URLS=["http://localhost:11434"]
DEFAULT_MODEL="qwen2.5:7b-instruct-q8_0"

# Model Parameters
MODEL_TEMPERATURE=0.7
MAX_TOKENS=4096

# Feature Flags
FUNCTION_CALLS_ENABLED=true

# Application Settings
LOG_LEVEL=DEBUG

# OpenAI Configuration (Optional)
# OPENAI_API_KEY=your_api_key_here
# OPENAI_ORG_ID=your_org_id_here

# Security Settings
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600  # In seconds

# CORS Settings (customize for production)
ALLOWED_ORIGINS=["*"]

# Chroma Configuration
CHROMA_PERSIST_DIRECTORY=chroma_data
CHROMA_COLLECTION_NAME=desktop_llm_memory

# MCP Configuration
MCP_SERVER_FILESYSTEM_PATH=./src/filesystem/dist/index.js
MCP_SERVER_FILESYSTEM_COMMAND=node
MCP_WORKSPACE_DIR=./data

PYTHONPATH=.
